{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2ce71-4dfe-4715-9059-42886b5876cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from ultralytics import YOLO\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c32f03-f220-4e33-8adc-18f5d7145a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "try:\n",
    "    sym_spell.load_dictionary(\"ru_full.txt\", term_index=0, count_index=1, encoding='utf-8')\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки словаря: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23a037-3c29-4b74-9568-99de14a67a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    yolo_model = YOLO(\"best.pt\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки модели YOLO: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b457023-8407-4509-95aa-4e7dfa71c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EgeEvaluator:\n",
    "    def __init__(self, model_path, device=None):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, text):\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        pred = torch.argmax(probs).item()\n",
    "        return pred, probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb869d6-9211-4ef8-9c94-fba3d5333108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text):\n",
    "    suggestions = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "    return suggestions[0].term if suggestions else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837f320-6e6d-4ce6-b756-f0051c4b3416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_webres(webres_path):\n",
    "    try:\n",
    "        with open(webres_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка чтения {webres_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    text_boxes = []\n",
    "\n",
    "    def parse_element(element):\n",
    "        if isinstance(element, dict):\n",
    "            if 'languages' in element:\n",
    "                for lang in element['languages']:\n",
    "                    if lang.get('lang') == 'rus':\n",
    "                        for text_item in lang.get('texts', []):\n",
    "                            text = text_item.get('text', '').strip()\n",
    "                            if text:\n",
    "                                corrected = correct_text(text)\n",
    "                                box = {\n",
    "                                    'x': element.get('x', 0),\n",
    "                                    'y': element.get('y', 0),\n",
    "                                    'w': element.get('w', 0),\n",
    "                                    'h': element.get('h', 0),\n",
    "                                    'text': corrected\n",
    "                                }\n",
    "                                text_boxes.append(box)\n",
    "            for value in element.values():\n",
    "                parse_element(value)\n",
    "        elif isinstance(element, list):\n",
    "            for item in element:\n",
    "                parse_element(item)\n",
    "\n",
    "    parse_element(data)\n",
    "    return text_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c725d-b346-4e91-97d1-fc5378450b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_boxes(image_path):\n",
    "    try:\n",
    "        results = yolo_model(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка обработки изображения {image_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    yolo_boxes = []\n",
    "    print(f\"\\nДетекция для {image_path}:\")\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            xyxy = box.xyxy[0].tolist()\n",
    "            cls_id = int(box.cls)\n",
    "            conf = box.conf.item()\n",
    "            print(f\"  Класс: {cls_id}, Метка: {yolo_model.names[cls_id]}, Conf: {conf:.2f}, BBox: {xyxy}\")\n",
    "\n",
    "            yolo_boxes.append({\n",
    "                'x1': xyxy[0],\n",
    "                'y1': xyxy[1],\n",
    "                'x2': xyxy[2],\n",
    "                'y2': xyxy[3],\n",
    "                'label': cls_id\n",
    "            })\n",
    "    return yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbbce7-0f98-444e-a533-ff72330d61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_text_to_tasks(webres_boxes, yolo_boxes):\n",
    "    task_data = []\n",
    "    print(\"\\nСопоставление боксов:\")\n",
    "\n",
    "    for yolo_box in yolo_boxes:\n",
    "        task_num = yolo_box['label']\n",
    "        task_key = f\"Task_2{task_num + 2}\"\n",
    "        matched_texts = []\n",
    "\n",
    "        for webres_box in webres_boxes:\n",
    "            text_center_x = webres_box['x'] + webres_box['w'] / 2\n",
    "            text_center_y = webres_box['y'] + webres_box['h'] / 2\n",
    "\n",
    "            if (yolo_box['x1'] <= text_center_x <= yolo_box['x2'] and\n",
    "                    yolo_box['y1'] <= text_center_y <= yolo_box['y2']):\n",
    "                matched_texts.append(webres_box['text'])\n",
    "                print(f\"  Найдено совпадение: {task_key} -> '{webres_box['text']}'\")\n",
    "\n",
    "        if matched_texts:\n",
    "            combined_text = \" \".join(matched_texts)\n",
    "            task_data.append({\n",
    "                'task': task_key,\n",
    "                'text': combined_text\n",
    "            })\n",
    "\n",
    "    return task_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155579e7-69f1-4c31-99a1-b04ec9e92787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pairs(webres_dir, images_dir):\n",
    "    pairs = []\n",
    "    try:\n",
    "        webres_files = [f for f in os.listdir(webres_dir) if f.endswith('.webRes')]\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка чтения директории {webres_dir}: {e}\")\n",
    "        return pairs\n",
    "\n",
    "    for webres_file in webres_files:\n",
    "        base_name = os.path.splitext(webres_file)[0].split('__')[0]\n",
    "        image_file = f\"{base_name}.png\"\n",
    "        image_path = os.path.join(images_dir, image_file)\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            pairs.append((\n",
    "                os.path.join(webres_dir, webres_file),\n",
    "                image_path,\n",
    "                webres_file\n",
    "            ))\n",
    "        else:\n",
    "            print(f\"Предупреждение: Не найден .png файл для {webres_file}\")\n",
    "\n",
    "    print(f\"Найдено {len(pairs)} пар файлов\")\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562da14-142b-4d91-852e-ad3e27caa5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cc4d4-298d-405e-b535-2802a026c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(ground_truth_path):\n",
    "    if not ground_truth_path or not os.path.exists(ground_truth_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(ground_truth_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if isinstance(data, list) and len(data) > 0 and 'label' in data[0]:\n",
    "            return {clean_text(item['text']): item['label'] for item in data}\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка загрузки истинных оценок: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745c84f-80ea-411d-aea9-3723a2e5b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(webres_dir, images_dir, bert_model_path,\n",
    "                     ground_truth_path=None,\n",
    "                     output_file=\"results.json\"):\n",
    "    pairs = find_pairs(webres_dir, images_dir)\n",
    "    all_task_data = []\n",
    "\n",
    "    for webres_path, image_path, source_file in pairs:\n",
    "        print(f\"\\nОбработка: {source_file} + {os.path.basename(image_path)}\")\n",
    "        try:\n",
    "            webres_boxes = extract_text_from_webres(webres_path)\n",
    "            yolo_boxes = get_yolo_boxes(image_path)\n",
    "            task_data = match_text_to_tasks(webres_boxes, yolo_boxes)\n",
    "            all_task_data.extend(task_data)\n",
    "            print(f\"Найдено задач в текущей паре: {len(task_data)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка обработки пары: {e}\")\n",
    "\n",
    "    ground_truth = load_ground_truth(ground_truth_path)\n",
    "\n",
    "    bert_evaluator = EgeEvaluator(bert_model_path)\n",
    "\n",
    "    results = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    for task in all_task_data:\n",
    "        try:\n",
    "            clean_task_text = clean_text(task['text'])\n",
    "            pred_label, pred_probs = bert_evaluator.predict(clean_task_text)\n",
    "\n",
    "            result_entry = {\n",
    "                'task': task['task'],\n",
    "                'text': task['text'],\n",
    "                'predicted_label': pred_label,\n",
    "                'probabilities': pred_probs.tolist()\n",
    "            }\n",
    "\n",
    "            if ground_truth and clean_task_text in ground_truth:\n",
    "                true_label = ground_truth[clean_task_text]\n",
    "                result_entry['true_label'] = true_label\n",
    "                true_labels.append(true_label)\n",
    "                pred_labels.append(pred_label)\n",
    "\n",
    "            results.append(result_entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка классификации текста для {task['task']}: {e}\")\n",
    "\n",
    "    if true_labels:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"Результаты валидации модели\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Accuracy: {accuracy_score(true_labels, pred_labels):.4f}\")\n",
    "        print(f\"F1 Score (weighted): {f1_score(true_labels, pred_labels, average='weighted'):.4f}\")\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_labels, pred_labels, digits=4))\n",
    "\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(true_labels, pred_labels))\n",
    "\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(\"\\nПримеры результатов:\")\n",
    "        for result in results[:5]:\n",
    "            print(f\"\\nЗадача: {result['task']}\")\n",
    "            print(f\"Текст: {result['text'][:100]}...\")\n",
    "            print(f\"Предсказанная оценка: {result['predicted_label']}\")\n",
    "            if 'true_label' in result:\n",
    "                print(f\"Истинная оценка: {result['true_label']}\")\n",
    "            print(f\"Вероятности: {result['probabilities']}\")\n",
    "\n",
    "        print(f\"\\nВсего обработано {len(results)} задач. Результаты сохранены в {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка сохранения результатов: {e}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9b86a-2602-478b-a511-6b9984904ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    WEBRES_DIR = \"school (1)\"\n",
    "    IMAGES_DIR = \"dataset/val/images\"\n",
    "    BERT_MODEL_PATH = \"ege_bert_model\"\n",
    "    GROUND_TRUTH_PATH = \"bert_dataset.json\"\n",
    "\n",
    "    process_pipeline(\n",
    "        webres_dir=WEBRES_DIR,\n",
    "        images_dir=IMAGES_DIR,\n",
    "        bert_model_path=BERT_MODEL_PATH,\n",
    "        ground_truth_path=GROUND_TRUTH_PATH,\n",
    "        output_file=\"final_results.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e519a0-a9c3-4bb3-a329-11cecbdeea54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
